{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9fGH8hooLmKLKEGdC/qpB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# K-means clustering\n",
        "\n",
        "## Introduction\n",
        "\n",
        "The K-means algorithm is a distance-based unsupervised machine learning algorithm designed to seperate datapoints into clusters to help understand underlying patterns within the data. The entire process consists of a number of steps. They are:\n",
        "\n",
        "* The assignment step\n",
        "* The update step\n",
        "* The Objective function\n",
        "\n",
        "The overall goal of the algorithm is to reduce the overall euclidean distance between the datapoints and the centroid. The loss function that drives this algorithm is called Within Cluster Sum of Squares (WC-SSE).\n",
        "\n",
        "### Initialisation\n",
        "\n",
        "To initialise the kmeans algorithm, the $K$ value is assigned, telling the algorithm the number of clusters to work with. This can be found by initialising a loop to test a number of $K$ values and then compare the inertia values for each (see inertia section). An example of the plot used to compare can be seen below.\n",
        "\n",
        "** INSERT **\n",
        "\n",
        "## The assignment step\n",
        "\n",
        "This step looks at each data point and seeks to attach it to a centroid by finding which centroid is the closest. This happens by calculating the the distance to all and then finding the smallest value. When choosing the initial centroids, these are usually randomly picked datapoints. This can however, be assigned to a specific place (or a random place) although this may lead to slower convergence due to a lack of datapoints in that specific area.\n",
        "\n",
        "### Mathematical formula\n",
        "\n",
        "$$x_i \\in S_j \\iff j = \\underset{k}{\\arg\\min} ||x_i - \\mu_k||^2$$\n",
        "\n",
        "### Explanation\n",
        "\n",
        "* $x_i$: This is the position vector of a single data point\n",
        "* $x_i \\in S_j$: This means that the datapoint $x_i$ belongs to the cluster $S_j$. This is the final result of the rule.\n",
        "* $\\iff$: This is the mathematical symbol for iff or 'If and only if'. This is a double-sided relationship that establishes a **necessary and sufficient** condition for assignment. In this context it means that a data point can only be assigned to a centroid ($x_i \\in S_j$) **if and only if** that cluster provides the minimum squared euclidean distance.\n",
        "* $j =$: This is the variable that the stores the index of the best cluster\n",
        "* $\\underset{k}{\\arg\\min}$: This is the argument that minimises. This essentially asks which cluster index ($k$) gives the **minimum** value\n",
        "* $|| ||$: This designates the euclidean norm. The euclidean norm is the standard way of measuring the length or magnitude of a vector in euclidean space.\n",
        "* $||x_i - \\mu_k||^2$: This is the way of displaying the squared distance. This is minimising the distance between $x_i$ (the data point) and $\\mu_k$ (the centroid)\n",
        "\n",
        "When all of this is combined it spells out the following in standardised mathematical notation. 'A datapoint ($x_i$) is assigned to a cluster ($S_j$) **if and only if** that clusters centre ($\\mu_k$) is the closest one to it.\n",
        "\n",
        "## The update step\n",
        "\n",
        "The next step is the update step. This is where the algorithm the begins to calculate the mean euclidean distances between the datapoints and move the centroid to ensure it is the lowest possible value. In this movement, the only component that moves is the centroid, none of the datapoints move in this space.\n",
        "\n",
        "### The mathematical formula\n",
        "\n",
        "$$\\mathbf{\\mu}_j^{\\text{new}} = \\frac{1}{|S_j|} \\sum_{\\mathbf{x}_i \\in S_j} \\mathbf{x}_i$$\n",
        "\n",
        "### Explanation\n",
        "\n",
        "* $\\mathbf{\\mu}_j^{\\text{new}}$: This is the new centroid location\n",
        "* $\\frac{1}{|S_j|}$: This is the fraction that calculates the mean distance. The pipes (|) are used to indicate **cardinality** in the set. This means that $S_j$ is represented by the total count of datapoints in the cluster not the total.\n",
        "* $\\sum_{\\mathbf{x}_i \\in S_j} \\mathbf{x}_i$: This part is the condition for summation along with the vector being summed. What this is saying is that sum only those vectors ($x_i$) that the elements of ($\\in$) the cluster set $S_j$. The final $x_i$ is the term actually being summed.\n",
        "\n",
        "When this is all done, it will result in a new $\\mu_k$ which can then be fed into the objective function as well as used to recalculate the assignment step in the event that the centroid moves position. This is done on a loop until the centroid no longer needs to move due to convergence.\n",
        "\n",
        "## The objective function\n",
        "\n",
        "When referring to unsupervised machine learning algorithms, the term loss function is replaced with the term objective function. Whereas the loss function in a supervised machine learning system is there to measure the error between the prediction ($\\hat{y}$) and the true value ($y$), an objective function within an unsupervised system measures the error between the datapoint ($x_i$) and the cluster centre ($\\mu_k$).\n",
        "\n",
        "### The mathematical formula\n",
        "\n",
        "$$WC\\text{-}SSE = \\sum_{j=1}^{K} \\sum_{\\mathbf{x}_i \\in S_j} ||\\mathbf{x}_i - \\mathbf{\\mu}_j||^2$$\n",
        "\n",
        "### Explanation\n",
        "\n",
        "* $WC\\text{-}SSE$: This stands for the **Within-Cluster Sum of Squares** and is the objective function that will measure the euclidean distances between the centroid and the datapoints.\n",
        "* $\\sum_{j=1}^{K}$: This is the outer summation that sums the results for all $K$ clusters that are worked out from the inner summation.\n",
        "* $\\sum_{\\mathbf{x}_i \\in S_j}$: This is the inner summation. This has to be worked out first as this gives the output used for the outer summation. This is the summation that is applied to the euclidean distance calculation. So this sums all of the datapoints ($x_i$) that are elements ($\\in$) belonging to a specific cluster ($S_j$)\n",
        "* $||\\mathbf{x}_i - \\mathbf{\\mu}_j||^2$: This is squared euclidean distance between the datapoint ($x_i$) and the centroid ($\\mu_j$). This calculation gives you one single number and then you apply the summation rules for all datapoints.\n",
        "\n",
        "The algorithm iterates through the following steps.\n",
        "\n",
        "1. **Initialisation** - The algorithm randomly assigns"
      ],
      "metadata": {
        "id": "WVUWZQVwwy2H"
      }
    }
  ]
}