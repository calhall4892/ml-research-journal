{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwoy/o7lfoLhgXMhXODk9T"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The Mathematics of Linear Regression\n",
        "\n",
        "_Author: Callum Hall_\n",
        "\n",
        "_Date: 11/08/2025_"
      ],
      "metadata": {
        "id": "ELPeyP6A4ILv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 1: The Core Idea\n",
        "\n",
        "### 1.1 Overview\n",
        "\n",
        "This notebook is looking at the mathematics and theory that underpins linear regression models. Linear regression models are an algorithm that is used in classification problems. A traditional linear equation will not work in a classification problem because a linear regression model will provide an output that ranges from negative to positive infinity whereas a probability needs to be between 0-1. Therefore to do this, we have to apply a sigmoid transformation in order to ensure an output that will allow for probability problems.\n",
        "\n",
        "### 1.2 The General Equation\n",
        "\n",
        "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
        "\n",
        "The sigmoid function is what changes a simple linear regression function into a logistic regression function that outputs in a 0-1 format rather than a negative infinity - postitive infinity scale.\n",
        "\n",
        "The way the sigmoid function works is in the $e^{-z}$ which dictates whether the overall function is a very small number or very large number.\n",
        "\n",
        "The model works in two stages to produce a final probability.\n",
        "\n",
        "**1. The Linear Part**\n",
        "\n",
        "First, the model calculates a linear score, which we call $z$. This score can be any real number.\n",
        "\n",
        "$$z = Wx + b$$\n",
        "\n",
        "**2. The Sigmoid Part**\n",
        "\n",
        "Next, this linear score $z$ is passed as the input to the sigmoid function. This \"squashes\" the result into a probability between 0 and 1.\n",
        "\n",
        "$$P(x) = \\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
        "\n",
        "**The Final Equation**\n",
        "By combining these two stages, we get the final, full equation for logistic regression:\n",
        "\n",
        "$$P(x) = \\frac{1}{1 + e^{-(Wx+b)}}$$\n",
        "\n",
        "This final equation gives us the probability of a data point belonging to the positive class."
      ],
      "metadata": {
        "id": "KFNRvJsL4h-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 2: Log Odds"
      ],
      "metadata": {
        "id": "NWK3zo8v_AVR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E5Bd20pP-_1-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}